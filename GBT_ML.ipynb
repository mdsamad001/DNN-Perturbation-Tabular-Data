{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ClassifierModels as cm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dataset(df, y_column_name):\n",
    "    y = df[y_column_name]\n",
    "    X = df.drop([y_column_name], axis=1)\n",
    "\n",
    "    # standardize\n",
    "    sc = StandardScaler()\n",
    "    np_scaled = sc.fit_transform(X)\n",
    "    df_normalized = pd.DataFrame(np_scaled, columns = X.columns)\n",
    "\n",
    "    result = pd.concat([df_normalized, y], axis=1)\n",
    "\n",
    "    return result, np_scaled, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read files\n",
    "def file_reader(file_path):\n",
    "    '''Input = file path (str)\n",
    "       Output = numpy array of items in files\n",
    "    '''\n",
    "    \n",
    "    data = []\n",
    "    with open(file_path) as f:\n",
    "        reader = csv.reader(f, delimiter='\\n')\n",
    "        for row in reader:\n",
    "            for x in row:\n",
    "                x=x.split(' ')\n",
    "                example = []\n",
    "                for item in x:\n",
    "                    if item:\n",
    "                        item = int(item) #convert to int\n",
    "                        example.append(item)\n",
    "                data.append(example)\n",
    "        data = np.asarray(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## arcene\n",
    "dbName = 'arcene'\n",
    "\n",
    "arcene_train_X = file_reader('hd-datasets/ARCENE/arcene_train.data')\n",
    "arcene_test_X = file_reader('hd-datasets/ARCENE/arcene_valid.data')\n",
    "\n",
    "arcene_train_y = file_reader('hd-datasets/ARCENE/arcene_train.labels')\n",
    "arcene_train_y = np.ravel(arcene_train_y)\n",
    "arcene_test_y = file_reader('hd-datasets/ARCENE/arcene_valid.labels')\n",
    "arcene_test_y = np.ravel(arcene_test_y)\n",
    "\n",
    "arcene_train = np.column_stack( (arcene_train_X,arcene_train_y) )\n",
    "arcene_test = np.column_stack( (arcene_test_X,arcene_test_y) )\n",
    "arcene = np.row_stack( (arcene_train,arcene_test) )\n",
    "\n",
    "data_df = pd.DataFrame.from_records(arcene)\n",
    "y_column_name = 10000\n",
    "\n",
    "le = LabelEncoder()\n",
    "data_df[y_column_name] = le.fit_transform(data_df[y_column_name])\n",
    "\n",
    "y = data_df[y_column_name].to_numpy()\n",
    "X_data = data_df.drop([y_column_name], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        22\n",
      "           1       0.88      0.78      0.82        18\n",
      "\n",
      "    accuracy                           0.85        40\n",
      "   macro avg       0.85      0.84      0.85        40\n",
      "weighted avg       0.85      0.85      0.85        40\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89        22\n",
      "           1       0.93      0.78      0.85        18\n",
      "\n",
      "    accuracy                           0.88        40\n",
      "   macro avg       0.89      0.87      0.87        40\n",
      "weighted avg       0.88      0.88      0.87        40\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        22\n",
      "           1       0.67      0.67      0.67        18\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.70      0.70      0.70        40\n",
      "weighted avg       0.70      0.70      0.70        40\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88        23\n",
      "           1       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.85        40\n",
      "   macro avg       0.87      0.83      0.84        40\n",
      "weighted avg       0.86      0.85      0.85        40\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90        23\n",
      "           1       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.88        40\n",
      "   macro avg       0.89      0.86      0.87        40\n",
      "weighted avg       0.88      0.88      0.87        40\n",
      "\n",
      "arcene\n",
      "0.8300000000000001\n",
      "0.06595452979136461\n"
     ]
    }
   ],
   "source": [
    "clfmodel = 'GBT'\n",
    "accuracy_mean, accuracy_std = cm.crossValid (X_data, y, clfmodel, nfolds=5)\n",
    "\n",
    "print(dbName)\n",
    "print(accuracy_mean)\n",
    "print(accuracy_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gene\n",
    "dbName = 'gene'\n",
    "\n",
    "data_df = pd.read_csv('hd-datasets/gene/gene-modified.csv',dtype=np.float32)\n",
    "y_column_name = 'Class'\n",
    "y = data_df[y_column_name].to_numpy()\n",
    "X_data = data_df.drop([y_column_name], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99        60\n",
      "         1.0       1.00      1.00      1.00        16\n",
      "         2.0       1.00      0.97      0.98        29\n",
      "         3.0       1.00      1.00      1.00        28\n",
      "         4.0       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       1.00      0.99      0.99       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00        15\n",
      "         2.0       1.00      1.00      1.00        29\n",
      "         3.0       1.00      1.00      1.00        29\n",
      "         4.0       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           1.00       160\n",
      "   macro avg       1.00      1.00      1.00       160\n",
      "weighted avg       1.00      1.00      1.00       160\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99        60\n",
      "         1.0       0.94      1.00      0.97        15\n",
      "         2.0       0.97      1.00      0.98        30\n",
      "         3.0       1.00      0.96      0.98        28\n",
      "         4.0       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.99       160\n",
      "   macro avg       0.98      0.99      0.98       160\n",
      "weighted avg       0.99      0.99      0.99       160\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99        60\n",
      "         1.0       1.00      1.00      1.00        16\n",
      "         2.0       1.00      1.00      1.00        29\n",
      "         3.0       0.97      1.00      0.98        28\n",
      "         4.0       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.99       160\n",
      "   macro avg       0.99      1.00      0.99       160\n",
      "weighted avg       0.99      0.99      0.99       160\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98        60\n",
      "         1.0       1.00      0.94      0.97        16\n",
      "         2.0       1.00      1.00      1.00        29\n",
      "         3.0       1.00      0.96      0.98        28\n",
      "         4.0       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.99       160\n",
      "   macro avg       0.99      0.98      0.99       160\n",
      "weighted avg       0.99      0.99      0.99       160\n",
      "\n",
      "gene\n",
      "0.9925077639751553\n",
      "0.004679172048036797\n"
     ]
    }
   ],
   "source": [
    "clfmodel = 'GBT'\n",
    "accuracy_mean, accuracy_std = cm.crossValid (X_data, y, clfmodel, nfolds=5)\n",
    "\n",
    "print(dbName)\n",
    "print(accuracy_mean)\n",
    "print(accuracy_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gisette\n",
    "dbName = 'gisette'\n",
    "\n",
    "gisette_train_X = file_reader('hd-datasets/gisette/gisette_train.data')\n",
    "gisette_test_X = file_reader('hd-datasets/gisette/gisette_valid.data')\n",
    "\n",
    "gisette_train_y = file_reader('hd-datasets/gisette/gisette_train.labels')\n",
    "gisette_train_y = np.ravel(gisette_train_y)\n",
    "gisette_test_y = file_reader('hd-datasets/gisette/gisette_valid.labels')\n",
    "gisette_test_y = np.ravel(gisette_test_y)\n",
    "\n",
    "gisette_train = np.column_stack( (gisette_train_X,gisette_train_y) )\n",
    "gisette_test = np.column_stack( (gisette_test_X,gisette_test_y) )\n",
    "gisette = np.row_stack( (gisette_train,gisette_test) )\n",
    "\n",
    "data_df = pd.DataFrame.from_records(gisette)\n",
    "y_column_name = 5000\n",
    "\n",
    "le = LabelEncoder()\n",
    "data_df[y_column_name] = le.fit_transform(data_df[y_column_name])\n",
    "\n",
    "y = data_df[y_column_name].to_numpy()\n",
    "X_data = data_df.drop([y_column_name], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       700\n",
      "           1       0.99      0.97      0.98       700\n",
      "\n",
      "    accuracy                           0.98      1400\n",
      "   macro avg       0.98      0.98      0.98      1400\n",
      "weighted avg       0.98      0.98      0.98      1400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       700\n",
      "           1       0.98      0.98      0.98       700\n",
      "\n",
      "    accuracy                           0.98      1400\n",
      "   macro avg       0.98      0.98      0.98      1400\n",
      "weighted avg       0.98      0.98      0.98      1400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       700\n",
      "           1       0.97      0.97      0.97       700\n",
      "\n",
      "    accuracy                           0.97      1400\n",
      "   macro avg       0.97      0.97      0.97      1400\n",
      "weighted avg       0.97      0.97      0.97      1400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       700\n",
      "           1       0.98      0.98      0.98       700\n",
      "\n",
      "    accuracy                           0.98      1400\n",
      "   macro avg       0.98      0.98      0.98      1400\n",
      "weighted avg       0.98      0.98      0.98      1400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       700\n",
      "           1       0.98      0.96      0.97       700\n",
      "\n",
      "    accuracy                           0.97      1400\n",
      "   macro avg       0.97      0.97      0.97      1400\n",
      "weighted avg       0.97      0.97      0.97      1400\n",
      "\n",
      "gisette\n",
      "0.9758571428571429\n",
      "0.006184245949118102\n"
     ]
    }
   ],
   "source": [
    "clfmodel = 'GBT'\n",
    "accuracy_mean, accuracy_std = cm.crossValid (X_data, y, clfmodel, nfolds=5)\n",
    "\n",
    "print(dbName)\n",
    "print(accuracy_mean)\n",
    "print(accuracy_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## madelon\n",
    "dbName = 'madelon'\n",
    "\n",
    "madelon_train_X = file_reader('hd-datasets/MADELON/madelon_train.data')\n",
    "madelon_test_X = file_reader('hd-datasets/MADELON/madelon_valid.data')\n",
    "\n",
    "madelon_train_y = file_reader('hd-datasets/MADELON/madelon_train.labels')\n",
    "madelon_train_y = np.ravel(madelon_train_y)\n",
    "madelon_test_y = file_reader('hd-datasets/MADELON/madelon_valid.labels')\n",
    "madelon_test_y = np.ravel(madelon_test_y)\n",
    "\n",
    "madelon_train = np.column_stack( (madelon_train_X,madelon_train_y) )\n",
    "madelon_test = np.column_stack( (madelon_test_X,madelon_test_y) )\n",
    "madelon = np.row_stack( (madelon_train,madelon_test) )\n",
    "\n",
    "data_df = pd.DataFrame.from_records(madelon)\n",
    "y_column_name = 500\n",
    "\n",
    "le = LabelEncoder()\n",
    "data_df[y_column_name] = le.fit_transform(data_df[y_column_name])\n",
    "\n",
    "y = data_df[y_column_name].to_numpy()\n",
    "X_data = data_df.drop([y_column_name], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       260\n",
      "           1       0.84      0.81      0.82       260\n",
      "\n",
      "    accuracy                           0.83       520\n",
      "   macro avg       0.83      0.83      0.83       520\n",
      "weighted avg       0.83      0.83      0.83       520\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       260\n",
      "           1       0.82      0.82      0.82       260\n",
      "\n",
      "    accuracy                           0.82       520\n",
      "   macro avg       0.82      0.82      0.82       520\n",
      "weighted avg       0.82      0.82      0.82       520\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       260\n",
      "           1       0.85      0.84      0.84       260\n",
      "\n",
      "    accuracy                           0.84       520\n",
      "   macro avg       0.84      0.84      0.84       520\n",
      "weighted avg       0.84      0.84      0.84       520\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80       260\n",
      "           1       0.80      0.79      0.80       260\n",
      "\n",
      "    accuracy                           0.80       520\n",
      "   macro avg       0.80      0.80      0.80       520\n",
      "weighted avg       0.80      0.80      0.80       520\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       260\n",
      "           1       0.79      0.80      0.79       260\n",
      "\n",
      "    accuracy                           0.79       520\n",
      "   macro avg       0.79      0.79      0.79       520\n",
      "weighted avg       0.79      0.79      0.79       520\n",
      "\n",
      "madelon\n",
      "0.8165384615384615\n",
      "0.01909955233528482\n"
     ]
    }
   ],
   "source": [
    "clfmodel = 'GBT'\n",
    "accuracy_mean, accuracy_std = cm.crossValid (X_data, y, clfmodel, nfolds=5)\n",
    "\n",
    "print(dbName)\n",
    "print(accuracy_mean)\n",
    "print(accuracy_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parkinson\n",
    "dbName = 'parkinson'\n",
    "\n",
    "\n",
    "data_df = pd.read_csv('hd-datasets/parkinson/pd_speech_features.csv',dtype=np.float32)\n",
    "y_column_name = 'class'\n",
    "y = data_df[y_column_name].to_numpy()\n",
    "X_data = data_df.drop([y_column_name], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.56      0.68        39\n",
      "         1.0       0.87      0.96      0.91       113\n",
      "\n",
      "    accuracy                           0.86       152\n",
      "   macro avg       0.86      0.76      0.79       152\n",
      "weighted avg       0.86      0.86      0.85       152\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.63      0.72        38\n",
      "         1.0       0.89      0.96      0.92       113\n",
      "\n",
      "    accuracy                           0.87       151\n",
      "   macro avg       0.86      0.79      0.82       151\n",
      "weighted avg       0.87      0.87      0.87       151\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.61      0.73        38\n",
      "         1.0       0.88      0.98      0.93       113\n",
      "\n",
      "    accuracy                           0.89       151\n",
      "   macro avg       0.90      0.79      0.83       151\n",
      "weighted avg       0.89      0.89      0.88       151\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.63      0.75        38\n",
      "         1.0       0.89      0.98      0.93       113\n",
      "\n",
      "    accuracy                           0.89       151\n",
      "   macro avg       0.91      0.81      0.84       151\n",
      "weighted avg       0.90      0.89      0.89       151\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.67      0.74        39\n",
      "         1.0       0.89      0.96      0.92       112\n",
      "\n",
      "    accuracy                           0.88       151\n",
      "   macro avg       0.87      0.81      0.83       151\n",
      "weighted avg       0.88      0.88      0.88       151\n",
      "\n",
      "parkinson\n",
      "0.8796531892645522\n",
      "0.01109803603636851\n"
     ]
    }
   ],
   "source": [
    "clfmodel = 'GBT'\n",
    "accuracy_mean, accuracy_std = cm.crossValid (X_data, y, clfmodel, nfolds=5)\n",
    "\n",
    "print(dbName)\n",
    "print(accuracy_mean)\n",
    "print(accuracy_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## malware\n",
    "dbName = 'malware'\n",
    "\n",
    "df_1 = pd.read_csv('hd-datasets/VxHeaven/staDynVt2955Lab.csv',dtype=np.float32)\n",
    "df_2 = pd.read_csv('hd-datasets/VxHeaven/staDynVxHeaven2698Lab.csv',dtype=np.float32)\n",
    "\n",
    "frames = [df_1, df_2]\n",
    "data_df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "y_column_name = 'label'\n",
    "\n",
    "y = data_df[y_column_name].to_numpy()\n",
    "X_data = data_df.drop([y_column_name], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96       540\n",
      "         1.0       0.96      0.96      0.96       591\n",
      "\n",
      "    accuracy                           0.96      1131\n",
      "   macro avg       0.96      0.96      0.96      1131\n",
      "weighted avg       0.96      0.96      0.96      1131\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97       540\n",
      "         1.0       0.98      0.96      0.97       591\n",
      "\n",
      "    accuracy                           0.97      1131\n",
      "   macro avg       0.97      0.97      0.97      1131\n",
      "weighted avg       0.97      0.97      0.97      1131\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96       540\n",
      "         1.0       0.97      0.97      0.97       591\n",
      "\n",
      "    accuracy                           0.97      1131\n",
      "   macro avg       0.97      0.97      0.97      1131\n",
      "weighted avg       0.97      0.97      0.97      1131\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96       539\n",
      "         1.0       0.96      0.96      0.96       591\n",
      "\n",
      "    accuracy                           0.96      1130\n",
      "   macro avg       0.96      0.96      0.96      1130\n",
      "weighted avg       0.96      0.96      0.96      1130\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.97       539\n",
      "         1.0       0.98      0.96      0.97       591\n",
      "\n",
      "    accuracy                           0.97      1130\n",
      "   macro avg       0.97      0.97      0.97      1130\n",
      "weighted avg       0.97      0.97      0.97      1130\n",
      "\n",
      "malware\n",
      "0.9640892623803824\n",
      "0.004431369754707548\n"
     ]
    }
   ],
   "source": [
    "clfmodel = 'GBT'\n",
    "accuracy_mean, accuracy_std = cm.crossValid (X_data, y, clfmodel, nfolds=5)\n",
    "\n",
    "print(dbName)\n",
    "print(accuracy_mean)\n",
    "print(accuracy_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d39ae9fbfa3c0490838fdc176b78f7e789d0dfdf0adc89bd7b683769bf60ecc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
